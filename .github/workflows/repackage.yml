name: Repackage Bundles

on: workflow_call

jobs:
  split-tasks:
    runs-on: ubuntu-latest
    env:
      BUILD_DATA_DIR: .build-data
    outputs:
      parallel-jobs-number: ${{ steps.split-packages.outputs.parallel-jobs-number }}
      parallel-array: ${{ steps.split-packages.outputs.parallel-array }}
    steps:
      - uses: actions/checkout@v3
      - uses: google-github-actions/auth@v1
        with:
          credentials_json: '${{ secrets.GOOGLE_CREDENTIALS_KERNEL_CACHE }}'

      - uses: google-github-actions/setup-gcloud@v1
      
      - uses: ./.github/actions/env

      - name: Prepare Cache
        run: |
          mkdir -p "${BUILD_DATA_DIR}/cache"
          IFS=',' read -r -a bucket_names <<< "${KERNEL_BUNDLE_BUCKET}"
          for bucket in "${bucket_names[@]}"; do
            if [ ! -f "${BUILD_DATA_DIR}/cache/cache.yml" ]; then
              gsutil cp "${bucket}/cache.yml" "${BUILD_DATA_DIR}/cache/cache.yml" || true
            fi
          done
          touch "${BUILD_DATA_DIR}/cache/cache.yml"

      - name: Restore manifest
        uses: actions/download-artifact@v3
        with:
          # this is archived by the crawl workflow
          # see .github/workflows/crawl.yml for details
          name: kernel-crawler-manifest

      - name: List packages
        run: make list-files

      - name: Split package file
        id: split-packages
        run: |
          import math
          import os
          import json

          def chunks(data, chunk_size):
            c = []
            for i in range(chunk_size):
              c.append(data[i::chunk_size])
            return c

          packages = []
          with open('.build-data/packages.txt') as pkg:
            packages = list(map(str.strip, pkg.readlines()))

          parallel_jobs = math.ceil(len(packages) / 500)
          if parallel_jobs > 32:
            parallel_jobs = 32

          jobs = chunks(packages, parallel_jobs)
          parallel = list(range(parallel_jobs))

          combined = {id: jobs[id] for id in range(parallel_jobs)}

          with open(os.environ['GITHUB_OUTPUT'], 'w') as output:
            output.write(f'parallel-jobs-number={parallel_jobs}\n')
            output.write(f'parallel-array={json.dumps(parallel)}\n')

          with open('jobs.json', 'w') as j:
            j.write(json.dumps(combined))

        shell: python

      # This is primarily for sanity checking
      - name: Archive package list
        uses: actions/upload-artifact@v3
        with:
          name: kernel-repackage-list
          path: |
            .build-data/packages.txt

      - name: Archive Jobs and Cache
        uses: actions/upload-artifact@v3
        with:
          name: package-jobs
          path: |
            .build-data/cache/cache.yml
            jobs.json

  repackage:
    runs-on: ubuntu-latest
    needs: split-tasks
    if: ${{ needs.split-tasks.outputs.parallel-jobs-number > 0 }}
    strategy:
      fail-fast: false
      matrix:
        packer: ${{ fromJSON(needs.split-tasks.outputs.parallel-array) }}
    env:
      MANIFEST_FILE: ./kernel-package-lists/manifest.yml
      BUILD_DATA_DIR: .build-data
    steps:
      - uses: actions/checkout@v3
      - uses: google-github-actions/auth@v1
        with:
          credentials_json: '${{ secrets.GOOGLE_CREDENTIALS_KERNEL_CACHE }}'

      - uses: google-github-actions/setup-gcloud@v1

      - uses: ./.github/actions/env

      - name: Build packers
        run: make packers

      - name: Restore manifest
        uses: actions/download-artifact@v3
        with:
          # this is archived by the crawl workflow
          # see .github/workflows/crawl.yml for details
          name: kernel-crawler-manifest

      - name: Download Jobs and Cache
        uses: actions/download-artifact@v3
        with:
          name: package-jobs

      - name: Write package file
        run: |
          import os
          import json

          with open('jobs.json') as jobs:
            packages = json.load(jobs)

          with open(os.environ['BUILD_DATA_DIR'] +'/packages.txt', 'w') as output:
            for package in packages["${{ matrix.packer }}"]:
              output.write(package + "\n")
        shell: python

      - name: Repackage
        run: |
          mkdir -p "${BUILD_DATA_DIR}/packages"

          # split into 100 line chunks, to avoid overloading the node
          # with huge amounts of package downloads
          split -l 100 --numeric-suffixes "${BUILD_DATA_DIR}/packages.txt" "${BUILD_DATA_DIR}/chunk"
          
          #
          # Download each chunk of 100 packages, repackage them, upload to
          # the bucket, and then clean up to keep disk usage low
          #
          for chunk in "${BUILD_DATA_DIR}"/chunk*; do
            ./scripts/download-packages "${BUILD_DATA_DIR}" "${KERNEL_PACKAGE_BUCKET}" "${chunk}"
            
            go run ./tools/repackage-kernels/main.go \
                -manifest "${MANIFEST_FILE}" \
                -cache-dir "${BUILD_DATA_DIR}/cache" \
                -pkg-dir "${BUILD_DATA_DIR}/packages" \
                -bundle-dir "${BUILD_DATA_DIR}/bundles" \
                -action build

            ./scripts/upload-bundles "${BUILD_DATA_DIR}" "$KERNEL_BUNDLE_BUCKET"

            # clean up repackaged bundles and packages
            rm -rf "${BUILD_DATA_DIR}/packages/*"
            rm -rf "${BUILD_DATA_DIR}/bundles/*"
          done

      - name: Cache
        run: make combine-cache clean-cache

      - name: Upload cache
        run: |
          IFS=',' read -r -a bucket_names <<< "${KERNEL_BUNDLE_BUCKET}"
          gsutil cp .build-data/cache/cache.yml "${bucket_names[0]}/cache.yml"

      - name: Commit to Collector Repo
        if: ${{ github.event_name != 'pull_request' }}
        run: make robo-collector-commit
        env:
          ROBOT_ROX_GITHUB_TOKEN: ${{ secrets.ROBOT_ROX_GITHUB_TOKEN }}
  notify:
    runs-on: ubuntu-latest
    needs:
      - split-tasks
      - repackage
    if: always() && contains(join(needs.*.result, ','), 'failure') && github.event_name == 'push'
    steps:
      - name: Notify Oncall
        uses: rtCamp/action-slack-notify@v2
        env:
          SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK_ONCALL }}
          SLACK_CHANNEL: oncall
          SLACK_COLOR: failure
          SLACK_LINK_NAMES: true
          SLACK_TITLE: Kernel Repackaging Failed
          MSG_MINIMAL: actions url,commit
          SLACK_MESSAGE: |
            @collector-team
